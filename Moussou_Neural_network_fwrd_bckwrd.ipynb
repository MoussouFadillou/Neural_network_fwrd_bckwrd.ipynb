{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moussou_Neural_network_fwrd_bckwrd.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZvyYLodFmE3"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU5sKoiz8j7y",
        "outputId": "8bf593cb-2232-4836-ddac-b7eec45cd443"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ljfrz1_fse",
        "outputId": "57940ed1-1d03-47e8-bc01-990cb98514c3"
      },
      "source": [
        "cd drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxdp2E1F_w6o",
        "outputId": "7b2f5788-ef23-43e7-dad2-9ac0db5b1f77"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6v8WAAx-pb1"
      },
      "source": [
        "from dlc_practical_prologue import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivFehhBj_HNW",
        "outputId": "dc0183e7-b19b-4856-82c1-9a0fab6c81e0"
      },
      "source": [
        "train_input, train_target, test_input, test_target=load_data(cifar=True,one_hot_labels=True,normalize=True,flatten=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Using CIFAR\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "** Reduce the data-set (use --full for the full thing)\n",
            "** Use 1000 train and 1000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUk_ggi3A470",
        "outputId": "e9ff0789-abea-4dd1-c060-8b0d4a292740"
      },
      "source": [
        "train_input.shape, train_target.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 3072]), torch.Size([1000, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O0xZuKzbenx",
        "outputId": "17549c41-668b-4a49-b4b6-01888f64c8f3"
      },
      "source": [
        "train_input[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3072])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1Vfn5k_rB2v"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "#mnist_train = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "#mnist_test = datasets.MNIST(\"data\", train=False, download=True, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-4u8w1_W431"
      },
      "source": [
        "#print(mnist_train)\n",
        "#print(mnist_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmwjRZvkcLkP"
      },
      "source": [
        "#mnist_train[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmPYcv4Bc01X"
      },
      "source": [
        "#a = torch.flatten(mnist_train[0][0])\n",
        "#a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prkGFSG7COT7"
      },
      "source": [
        "#1)Let us write the activation function et his derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tayNOishBE73"
      },
      "source": [
        "\n",
        "def sigma(x):\n",
        "  tanh=torch.tanh(x)\n",
        "  return tanh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9AT53SeQ90A"
      },
      "source": [
        "def dsigma(x):\n",
        "  dtanh= 1- torch.pow(torch.tanh(x),2)\n",
        "  return dtanh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnksL8LuULRk"
      },
      "source": [
        "#2)Let us write the function loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSNLaCZSRhZX"
      },
      "source": [
        "def loss(v,t):\n",
        "  loss=torch.norm(v - t)\n",
        "  return torch.pow(loss,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4UbcGPhWmu6"
      },
      "source": [
        "def dloss(v,t):\n",
        "  return 2*(v - t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yI9e7kgEoK"
      },
      "source": [
        "#def dloss(v,t):\n",
        "  #v=v.requires_grad(v)\n",
        "  #l=loss(v,t)\n",
        "  #l.backward()\n",
        "  #return v.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPKsbuchZCTO"
      },
      "source": [
        "#3Let us write the function for forward and backward\n",
        "#********forward\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mntvBG2rYz87"
      },
      "source": [
        "def forward_pass(w1, b1, w2, b2, x):\n",
        "  x0=x\n",
        "  s1=torch.mm(w1,x0) + b1\n",
        "  x1= sigma(s1)\n",
        "  s2=torch.mm(w2,x1) + b2\n",
        "  x2=sigma(s2)\n",
        "  return x0, s1, x1,s2,x2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXH0XKVvllgR"
      },
      "source": [
        "#*******backward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tey3ZpyOTyA1"
      },
      "source": [
        "def backward_pass(w1,b1,w2,b2,t,x, s1, x1, s2, x2,dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
        "  #print(x.shape,s1.shape,w1.shape, b1.shape)\n",
        "  dl_dx2 = dloss(x2, t)\n",
        "  dx2_ds2 = dsigma(s2)\n",
        "  #print('dl_dx2:  ', dl_dx2.shape)\n",
        "  dl_ds2 = torch.mul(dl_dx2, dx2_ds2)\n",
        "  #print('dx2_ds2:  ', dx2_ds2.shape)\n",
        "  dl_dw2 += torch.mm(dl_ds2, torch.t(x1))\n",
        "  dl_db2 += dl_ds2\n",
        "  dl_dx1 = torch.mm(torch.t(w2), dl_ds2)\n",
        "  dx1_ds1 = dsigma(s1)\n",
        "  #print('dx1_ds1:  ', dx1_ds1.shape)\n",
        "  dl_ds1 = torch.mul(dl_dx1, dx1_ds1)\n",
        "  dl_dw1 += torch.mm(dl_ds1, torch.t(x))\n",
        "  dl_db1 += dl_ds1\n",
        "  return dl_dw1, dl_db1, dl_dw2, dl_db2\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMss1L9jMrGd"
      },
      "source": [
        "def error(test_set, test_target_set, w1, b1, w2, b2):\n",
        "    n = test_set.shape[0]\n",
        "    num_errors = 0\n",
        "    for i in range(n):\n",
        "        x = test_set[i].resize(test_set[i].shape[0], 1)\n",
        "        t = torch.argmax(test_target_set[i])\n",
        "        _, _, _, _, predicted = forward_pass(w1, b1, w2, b2, x)\n",
        "        predicted_class = torch.argmax(predicted, 0)\n",
        "        if t != predicted_class:\n",
        "            num_errors += 1\n",
        "    return num_errors/n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yG310Hi0MFa"
      },
      "source": [
        "#4)Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZC1mT9R0Ld-"
      },
      "source": [
        "def train():\n",
        "#4)1)let us load the data using the provided prologue.load˙data function, with one-hot label vectors\n",
        "#and normalized inputs. Multiply the target label vectors by ζ = 0.9 (so that they are strictly in\n",
        "#the value range of tanh\n",
        "  train_input, train_target, test_input, test_target= load_data(cifar=True, one_hot_labels=True,normalize=True, flatten=True)\n",
        "\n",
        "  test_target = test_target.type(torch.LongTensor)*0.9\n",
        "  train_target = train_target.type(torch.LongTensor)*0.9\n",
        "  eps = 0.0000001\n",
        "  print(eps)\n",
        "#4)2)let us create the four weight and bias tensors, and fill them with random values sampled according to N(0,eps \u000f) with \u000f eps= 1e − 6.\n",
        "  \n",
        "  w1 = torch.zeros(50, 3072).normal_(0, eps)\n",
        "  b1 = torch.zeros(50, 1).normal_(0, eps)\n",
        "  w2 = torch.zeros(10, 50).normal_(0, eps)\n",
        "  b2 = torch.zeros(10, 1).normal_(0, eps)\n",
        "#4)3) let create the four tensors to sum up the gradients on individual samples, with respect to the weights and biases\n",
        "  eta = 0.1/train_input.shape[0]\n",
        "  for i in range(1000):\n",
        "    dl_dw1 = torch.zeros(50, 3072)\n",
        "    dl_db1 = torch.zeros(50, 1)\n",
        "    dl_dw2 = torch.zeros(10, 50)\n",
        "    dl_db2 = torch.zeros(10, 1)\n",
        "#4)3)4\n",
        "    for j in range(1000):\n",
        "      x = train_input[j].resize_(3072, 1)\n",
        "      t = train_target[j,:].reshape(-1,1)\n",
        "      x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, x)\n",
        "      backward_pass(w1, b1, w2, b2, t, x, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
        "    w1 = w1 - eta * dl_dw1\n",
        "    w2 = w2 - eta * dl_dw2\n",
        "    b1 = b1 - eta * dl_db1\n",
        "    b2 = b2 - eta * dl_db2\n",
        "  print(\"Training error: \", error(train_input, train_target, w1, b1, w2, b2))\n",
        "  print(\"Test error: \", error(test_input, test_target, w1, b1, w2, b2))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0uHejk0N03m",
        "outputId": "f387e4a6-d056-4a71-bacd-4c183c1e7024"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Using CIFAR\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "** Reduce the data-set (use --full for the full thing)\n",
            "** Use 1000 train and 1000 test samples\n",
            "1e-07\n",
            "Training error:  0.062\n",
            "Test error:  0.742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:474: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}